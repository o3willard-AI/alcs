# ==============================================================================
# ALCS (A Dual-Agent Local Coding Service) - Environment Configuration
# ==============================================================================
#
# This file contains all environment variables needed to configure ALCS.
# Copy this file to .env and update values as needed:
#   cp .env.example .env
#
# For AI Agents: All values below have sensible defaults for local development.
# Update OLLAMA_BASE_URL if your Ollama server is on a different host.
#
# ==============================================================================

# ------------------------------------------------------------------------------
# DATABASE CONFIGURATION
# ------------------------------------------------------------------------------

# SQLite database file location (recommended for development)
# For production, consider PostgreSQL:
#   postgresql://user:password@localhost:5432/alcs
DATABASE_URL="file:./prisma/dev.db"

# ------------------------------------------------------------------------------
# LLM PROVIDER CONFIGURATION
# ------------------------------------------------------------------------------

# Ollama Server Base URL
# Default: http://localhost:11434 (local Ollama installation)
# Remote: http://your-ollama-server:11434
OLLAMA_BASE_URL="http://localhost:11434"

# Alternative: Use Anthropic Claude API (if available)
# ANTHROPIC_API_KEY="sk-ant-..."
# ANTHROPIC_BASE_URL="https://api.anthropic.com"

# Alternative: Use OpenAI API (if available)
# OPENAI_API_KEY="sk-..."
# OPENAI_BASE_URL="https://api.openai.com/v1"

# ------------------------------------------------------------------------------
# AGENT ALPHA CONFIGURATION (Code Generator)
# ------------------------------------------------------------------------------

# Model to use for code generation
# Ollama options: qwen2.5-coder:32b, codellama:34b, deepseek-coder:33b
# Anthropic: claude-sonnet-4-5-20241022
# OpenAI: gpt-4, gpt-4-turbo
AGENT_ALPHA_MODEL="qwen2.5-coder:32b"

# Provider: ollama | anthropic | openai
AGENT_ALPHA_PROVIDER="ollama"

# Custom system prompt (optional)
# AGENT_ALPHA_SYSTEM_PROMPT="You are an expert code generator..."

# ------------------------------------------------------------------------------
# AGENT BETA CONFIGURATION (Code Reviewer/Critic)
# ------------------------------------------------------------------------------

# Model to use for code review
# Ollama options: deepseek-r1:14b, llama3:70b, mixtral:8x7b
# Anthropic: claude-sonnet-4-5-20241022
# OpenAI: gpt-4, gpt-4-turbo
AGENT_BETA_MODEL="deepseek-r1:14b"

# Provider: ollama | anthropic | openai
AGENT_BETA_PROVIDER="ollama"

# Custom system prompt (optional)
# AGENT_BETA_SYSTEM_PROMPT="You are an expert code reviewer..."

# ------------------------------------------------------------------------------
# SESSION CONFIGURATION
# ------------------------------------------------------------------------------

# Maximum number of review-revise iterations before escalation
# Range: 1-10, Default: 5
DEFAULT_MAX_ITERATIONS=5

# Quality score threshold for approval (0-100)
# Code must score above this to be approved
# Range: 0-100, Default: 85
DEFAULT_QUALITY_THRESHOLD=85

# Maximum time for a single task (minutes)
# Range: 1-120, Default: 30
TASK_TIMEOUT_MINUTES=30

# ------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ------------------------------------------------------------------------------

# Log level: error | warn | info | debug
# Default: info
LOG_LEVEL="info"

# Log file location (optional)
# If not set, logs to console only
# LOG_FILE="./logs/alcs.log"

# Enable structured logging (JSON format)
# Default: false
# STRUCTURED_LOGGING="false"

# ------------------------------------------------------------------------------
# SECURITY CONFIGURATION
# ------------------------------------------------------------------------------

# JWT Secret for MCP authentication (if using secure MCP server)
# Generate with: openssl rand -base64 32
# JWT_SECRET="your-secret-key-here"

# Enable authentication for MCP server
# Default: false (no auth for local development)
# MCP_REQUIRE_AUTH="false"

# Allowed origins for CORS (comma-separated)
# MCP_ALLOWED_ORIGINS="http://localhost:3000,https://your-frontend.com"

# ------------------------------------------------------------------------------
# MCP SERVER CONFIGURATION
# ------------------------------------------------------------------------------

# MCP server port
# Default: 3100
# MCP_PORT=3100

# MCP server host
# Default: localhost (only accessible locally)
# Set to 0.0.0.0 to allow external connections
# MCP_HOST="localhost"

# SSE (Server-Sent Events) timeout (seconds)
# MCP_SSE_TIMEOUT=300

# ------------------------------------------------------------------------------
# DEPLOYMENT CONFIGURATION
# ------------------------------------------------------------------------------

# Deployment mode: workstation | server | distributed
# workstation: Single machine, local LLMs
# server: Centralized server with shared LLM access
# distributed: Multiple workers with load balancing
DEPLOYMENT_MODE="workstation"

# Node environment: development | production | test
NODE_ENV="development"

# ------------------------------------------------------------------------------
# ADVANCED CONFIGURATION
# ------------------------------------------------------------------------------

# Enable experimental features
# ENABLE_EXPERIMENTAL_features="false"

# Cache directory for LLM responses (optional)
# CACHE_DIR="./cache"

# Enable metrics collection (Prometheus)
# ENABLE_METRICS="false"

# Metrics port
# METRICS_PORT=9090

# Rate limiting (requests per minute)
# RATE_LIMIT_PER_MINUTE=60

# ------------------------------------------------------------------------------
# ORGANIZATIONAL POLICIES (Optional)
# ------------------------------------------------------------------------------

# Path to custom security policy file
# SECURITY_POLICY_PATH="./policies/security-policy.yaml"

# Path to custom style guide
# STYLE_GUIDE_PATH="./policies/style-guide.yaml"

# Path to custom testing policy
# TESTING_POLICY_PATH="./policies/testing-policy.yaml"

# ==============================================================================
# END OF CONFIGURATION
# ==============================================================================
